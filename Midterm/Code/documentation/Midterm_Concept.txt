
Bolor Amgalan.................
Midterm Project...............



Project Name: 

"SYNERGIZE"



Concept:

With the advent of more robust machine learning algorithms, future creative tasks 
will be increasingly performed by machines of all forms and capability. The question
we might want to ask ourselves, then, is what happens to traditional craft skills
when we no longer use them? What happens to human talent when we no longer cherish
and develop them?

SYNERGIZE is an AI powered visual ideation tool that will allow designers to augment,
not replace, their talent by finding/identifying a synergy in a collection of visual 
references. The typical workflow for a designer would be to upload pictures of their 
past projects, as well as additional visual references they find inspirational, and 
then, from the resulting collection of images, select an X number of random images 
for the AI to analyse. 

The SYNERGIZE AI will then analyze these images and display information on what kinds
of objects and references it is able to detect in all selected images. By identifying
the similarity of the selected images using the machine vision, the designer will be 
able to find previously unknown synergy between the images.

The output is currently envisaged as text (keywords), which will act as inspiration,
or reference points, for the designer. But moving forwardm various other machine
learning techniques could be implemented where the AI identifies visually similar
features in the images, combines them, or processes them in some other way, and then
displays the final end result as a new machine generated image or series of images.

The premise for this project is that machine learning models often identify
things/objects/features in images that normal humans do not see in them. Sometimes it
is a mistake by the machine that results from poor training data, but sometimes the
output is highly accurate, detecting a pattern the human eyes did not see before.

For my midterm, I developed the initial mockup of this app using a JSON file of images
and jQuery. My initial plan to also incorporate a machine learning feature extraction
library using p5.js (model built with MobileNet) did not succeed as the complexity of
the p5.js related code kept breaking my other code that was functioning okay. But I 
would like to continue working on this over the break and get it to work as it would 
be really interesting to see how the machine learning feature extractor affects my own
creative thought process and what it reveals to me about the images I select that I 
did not see previously.